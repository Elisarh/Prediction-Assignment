---
title: "Practical Machine Learning Project"
author: "Elisa Reyes"
date: "24 de noviembre de 2017"
output: html_document
---
##Overview

 At this project, we have to build a predictor and we are going to use the data from the source:http://groupware.les.inf.puc-rio.br/har. This is a recolection of data from accelerometers of 6 participants, performing barbell lifts correctly and incorrectly. Our job will be to build a predictor who can predict how is the activity done.
 
##Loading Data

  The first thing, is to load the data. For our goal, we need the variable "classe", which is in the trainig set. 
```{r, echo=TRUE}
url_training<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_testing<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
file_training<-"pml-training.csv"
file_testing<-"pml-testing.csv"
download.file(url=url_training,destfile=file_training)
download.file(url=url_testing,destfile=file_testing)
df_training<-read.csv(file_training)
df_testing<-read.csv(file_testing)
summary(df_training$classe)
dim(df_training)
```

## Procesing Data

  Before continuing, this libraries are going to be used and we will load them:
```{r, echo=TRUE}
library(caret)
library(randomForest)
library(AppliedPredictiveModeling)
```
  
   Now, we are going to split the data, 60 percent for training porpouse and the rest for testing:
```{r,echo=TRUE}
inTrain<-createDataPartition(y=df_training$classe,p=0.6,list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]
dim(training)
dim(testing)
```
 We clean and order the data a little bit. We are going to remove the first 7 columns, because after taking a pick, we could see that they are not going to give us any usefull information. Then, we will remove too the columns with too many NA values and we will check for variantes that have zero variabillity.
```{r, echo =TRUE}
set.seed(123654)
nzv<-nearZeroVar(training)
training<-training[, -nzv]
testing<-testing[, -nzv]
dim(training)
```

```{r,echo=TRUE}
training<-training[,-c(1:7)]
testing<-testing[,-c(1:7)]
```

## Train a Model: Random Forest Model

   We have our testing group ready, so now we are going to apply the Random Forest model, because it was said at the lectures that it has very good results. I use a K-fold cross-validation of 3, becuase with a higher number, the time of performance was really high :
```{r,echo=TRUE}
train_rd<-train(classe~ .,data=training,method="rf",trControl=trainControl(method = "cv",number=3))
print(train_rd)
```
```{r,echo=TRUE}
train_rd$finalModel
```
The error rate is less than 1%, what itÂ´s great and something to expect from a random Forest procedure. So,this method will be applied to our test set and see what result we get.

```{r, echo=TRUE}
test3<-predict(train_rd,newdata = testing)
confusionMatrix(testing$classe,test3)
``` 

## Applied the predictor to submit the answer of the assignment

```{r,echo=TRUE}
final<-predict(train_rd,newdata = test)
print(final)
pml_write_files=function(x){
  n=length(x)
  for(i in 1:n){
    filename=paste0("problem_id",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names = FALSE,col.names = FALSE)
  }
}
pml_write_files(final)
```
